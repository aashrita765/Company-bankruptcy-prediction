# Company-bankruptcy-prediction

ğŸ’¼ Company Bankruptcy Prediction â€“ Project Summary

ğŸ“Š Objective: Built a machine learning system to predict whether a company will go bankrupt based on its financial indicators.

ğŸ’¡ Business Motivation: Early bankruptcy detection assists investors, auditors, and banks in identifying high-risk firms and preventing financial loss.

ğŸ§¾ Dataset: Sourced from Kaggle â€” contained numerical financial ratios like ROA, debt ratio, working capital, current ratio, and profitability measures.

ğŸ§¹ Data Cleaning: Used klib and pandas to remove duplicates, handle missing values, and eliminate constant or redundant columns.

ğŸ“ˆ Exploratory Data Analysis (EDA): Visualized distributions and correlations to understand feature relationships and detect outliers.

âš–ï¸ Class Imbalance Handling: Applied SMOTE (Synthetic Minority Oversampling Technique) to generate synthetic bankrupt company samples, balancing both classes.

âš™ï¸ Feature Scaling: Standardized numerical features using StandardScaler to ensure equal importance across all variables.

ğŸ¤– Models Implemented: Trained and compared five algorithms â€”

Logistic Regression (baseline linear model)

Random Forest (bagging ensemble)

XGBoost (boosting ensemble)

K-Nearest Neighbors (distance-based model)

Deep Neural Network (nonlinear representation learning using TensorFlow)

ğŸ§  Model Training: Split data into 80% training and 20% testing; trained each model on balanced and standardized data.

ğŸ“Š Evaluation Metrics: Measured performance using Accuracy, Precision, Recall, F1-score, and ROCâ€“AUC for fair comparison.

ğŸ† Best Model: XGBoost achieved the highest performance â€” 98.5% accuracy and AUC = 1.00, indicating perfect separation between bankrupt and non-bankrupt firms.

ğŸ“‰ Other Results:

Random Forest: AUC = 1.00, Accuracy â‰ˆ 90.8%

DNN & KNN: Accuracy â‰ˆ 93.9%, AUC â‰ˆ 0.94â€“0.98

Logistic Regression: Accuracy â‰ˆ 90.8%, AUC = 0.96

ğŸ§© Insights: Ensemble models (Random Forest, XGBoost) captured complex financial dependencies better than linear or distance-based models.

âš™ï¸ Tools & Libraries: Python, pandas, NumPy, scikit-learn, imbalanced-learn, TensorFlow/Keras, Matplotlib, klib.

ğŸš€ Future Enhancements:

Perform hyperparameter tuning (GridSearchCV/Optuna).

Add explainability (SHAP or LIME).

Incorporate time-series trends for better financial forecasting.
